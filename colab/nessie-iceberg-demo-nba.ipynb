{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nessie Spark SQL Demo with NBA Dataset\n",
    "============================\n",
    "This demo showcases how to use Nessie Python API along with Spark3 from Iceberg\n",
    "\n",
    "Initialize Pyspark + Nessie environment\n",
    "----------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# install the nessiedemo lib, which configures all required dependencies\n",
    "!pip install -i https://test.pypi.org/simple/ nessiedemo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Setup the Demo: installs the required Python dependencies, downloads the sample datasets and\n",
    "# downloads + starts the Nessie-Quarkus-Runner.\n",
    "from nessiedemo.demo import setup_demo\n",
    "demo = setup_demo(\"nessie-0.5-iceberg-0.11.yml\", [\"nba\"])\n",
    "\n",
    "# This is separate, because NessieDemo.prepare() via .start() implicitly installs the required dependencies.\n",
    "# Downloads Spark and sets up SparkSession, SparkContext, JVM-gateway\n",
    "from nessiedemo.spark import spark_for_demo\n",
    "spark, sc, jvm, demo_spark = spark_for_demo(demo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up nessie branches\n",
    "----------------------------\n",
    "\n",
    "- Branch `main` already exists\n",
    "- Create branch `dev`\n",
    "- List all branches (pipe JSON result into jq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new dev branch\n",
    "!nessie branch dev\n",
    "\n",
    "# session for dev branch\n",
    "spark_dev = demo_spark.session_for_ref(\"dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all branches\n",
    "!nessie --verbose branch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create tables under dev branch\n",
    "-------------------------------------\n",
    "\n",
    "We create two tables under the `dev` branch using the `spark_dev` session:\n",
    "- `salaries`\n",
    "- `totals_stats`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "dataset = demo.fetch_dataset(\"nba\")\n",
    "\n",
    "# Creating salaries table\n",
    "spark_dev.sql(\"CREATE TABLE IF NOT EXISTS nessie.nba.salaries (Season STRING, Team STRING, Salary STRING, Player STRING) USING iceberg\")\n",
    "salaries_df = spark_dev.read.csv(dataset[\"salaries.csv\"], header=True)\n",
    "salaries_df.write.format(\"iceberg\").mode(\"overwrite\").save(\"nessie.nba.salaries\")\n",
    "\n",
    "# Creating totals_stats table\n",
    "spark_dev.sql(\"CREATE TABLE IF NOT EXISTS nessie.nba.totals_stats (Season STRING, Age STRING, Team STRING, ORB STRING, DRB STRING, TRB STRING, AST STRING, STL STRING, BLK STRING, TOV STRING, PTS STRING, Player STRING, RSorPO STRING) USING iceberg\")\n",
    "totals_stats_df = spark_dev.read.csv(dataset[\"totals_stats.csv\"], header=True)\n",
    "totals_stats_df.write.format(\"iceberg\").mode(\"overwrite\").save(\"nessie.nba.totals_stats\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# notice how we view the data of the salaries table on the dev branch via @dev\n",
    "spark.sql(\"select * from nessie.nba.`salaries@dev`\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check generated tables\n",
    "----------------------------\n",
    "\n",
    "Check tables generated under the `dev` branch (and that the `main` branch does not have any tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# there are no tables on the main branch\n",
    "!nessie contents --list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we should see the salaries & totals_stats tables on the dev branch\n",
    "!nessie contents --list --ref dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Note that the `dev` and `main` branches point to different commits now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all branches\n",
    "!nessie --verbose branch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dev promotion\n",
    "-------------\n",
    "\n",
    "Promote `dev` branch to `main`.\n",
    "\n",
    "* `main` now has the same tables as `dev`\n",
    "* `main` and `dev` point to the same commit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dev into main\n",
    "!nessie merge dev -b main --force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all branches\n",
    "!nessie --verbose branch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Create `etl` branch\n",
    "----------------------\n",
    "\n",
    "- Create a branch `etl` out of `main`\n",
    "- add data to `salaries`\n",
    "- alter the schema of `totals_stats`\n",
    "- create table `allstar_games_stats`\n",
    "- query the tables in `etl`\n",
    "- query the tables in `main`\n",
    "- promote `etl` branch to `main`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the etl branch based on main\n",
    "!nessie branch etl main\n",
    "\n",
    "# session for etl branch\n",
    "spark_etl = demo_spark.session_for_ref(\"etl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# add some salaries for Kevin Durant\n",
    "from pyspark.sql import Row\n",
    "Salary = Row(\"Season\", \"Team\", \"Salary\", \"Player\")\n",
    "kevin_durant = spark_etl.createDataFrame([\n",
    "    Salary(\"2017-18\", \"Golden State Warriors\", \"$25000000\", \"Kevin Durant\"),\n",
    "    Salary(\"2018-19\", \"Golden State Warriors\", \"$30000000\", \"Kevin Durant\"),\n",
    "    Salary(\"2019-20\", \"Brooklyn Nets\", \"$37199000\", \"Kevin Durant\"),\n",
    "    Salary(\"2020-21\", \"Brooklyn Nets\", \"$39058950\", \"Kevin Durant\")])\n",
    "kevin_durant.write.format(\"iceberg\").mode(\"append\").save(\"nessie.nba.salaries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping a column in the totals_stats table\n",
    "spark_etl.sql(\"ALTER TABLE nessie.nba.totals_stats DROP COLUMN Age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating allstar_games_stats table and viewing the contents\n",
    "spark_etl.sql(\"CREATE TABLE IF NOT EXISTS nessie.nba.allstar_games_stats (Season STRING, Age STRING, Team STRING, ORB STRING, TRB STRING, AST STRING, STL STRING, BLK STRING, TOV STRING, PF STRING, PTS STRING, Player STRING) USING iceberg\")\n",
    "allstar_games_stats_df = spark_etl.read.csv(dataset[\"allstar_games_stats.csv\"], header=True)\n",
    "allstar_games_stats_df.write.format(\"iceberg\").mode(\"overwrite\").save(\"nessie.nba.allstar_games_stats\")\n",
    "\n",
    "spark.sql(\"select * from nessie.nba.`allstar_games_stats@etl`\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allstar_games_stats is not on the main branch\n",
    "!nessie contents --list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we should see allstar_games_stats on the etl branch\n",
    "!nessie contents --list --ref etl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# now merge the etl branch into main\n",
    "!nessie merge etl -b main --force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# the etl and main branch should have the same revision\n",
    "!nessie --verbose branch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `experiment` branch\n",
    "--------------------------------\n",
    "\n",
    "- create `experiment` branch from `main`\n",
    "- drop `totals_stats` table\n",
    "- add data to `salaries` table\n",
    "- compare `experiment` and `main` tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the experiment branch from main\n",
    "!nessie branch experiment main\n",
    "\n",
    "# session for experiment branch\n",
    "spark_experiment = demo_spark.session_for_ref(\"experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the `totals_stats` table\n",
    "spark_experiment.sql(\"DROP TABLE IF EXISTS nessie.nba.totals_stats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add some salaries for Dirk Nowitzki\n",
    "Salary = Row(\"Season\", \"Team\", \"Salary\", \"Player\")\n",
    "dirk_nowitzki = spark_experiment.createDataFrame([\n",
    "    Salary(\"2015-16\", \"Dallas Mavericks\", \"$8333333\", \"Dirk Nowitzki\"),\n",
    "    Salary(\"2016-17\", \"Dallas Mavericks\", \"$25000000\", \"Dirk Nowitzki\"),\n",
    "    Salary(\"2017-28\", \"Dallas Mavericks\", \"$5000000\", \"Dirk Nowitzki\"),\n",
    "    Salary(\"2018-19\", \"Dallas Mavericks\", \"$5000000\", \"Dirk Nowitzki\")])\n",
    "dirk_nowitzki.write.format(\"iceberg\").mode(\"append\").save(\"nessie.nba.salaries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we should see the salaries and allstar_games_stats tables only\n",
    "!nessie contents --list --ref experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# main should still see the totals_stats table\n",
    "!nessie contents --list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the contents of the `salaries` table on the `experiment` branch.\n",
    "Notice the use of the `nessie` catalog and the use of `@experiment` to view data on the `experiment` branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"select count(*) from nessie.nba.`salaries@experiment`\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and compare to the contents of the `salaries` table on the `main` branch. Notice that we didn't have to specify `@branchName` as it defaulted\n",
    "to the `main` branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"select count(*) from nessie.nba.salaries\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
