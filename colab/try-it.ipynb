{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO Remove this - only people running notebooks in an IDE without the JAVA_HOME env need this.\n",
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/home/snazy/devel/openjdk/images/graalvm/jdk-11\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO This whole block will eventually become a     !pip install nessiedemo\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# TODO replace this block with the following, once nessiedemo is stable and released on pypi or at least pypi-test\n",
    "#   subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"nessiedemo\"])\n",
    "setup_path = \"{}/../setup\".format(os.getcwd())\n",
    "pkg_file = glob.glob(\"{}/dist/nessiedemo-*.whl\".format(setup_path))[0]\n",
    "result = subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"--force-reinstall\", pkg_file])\n",
    "if result.returncode != 0:\n",
    "    raise Exception(\"pip install failed: exit-code={}, stdout={}, stderr={}\".format(result.returncode, result.stdout, result.stderr))\n",
    "\n",
    "# TODO left here to keep the code during development, might be useful for binder.org, maybe\n",
    "# import importlib.util\n",
    "# spec = importlib.util.spec_from_file_location(\"nessiedemo.NessieDemo\", \"{}/nessiedemo/demo.py\".format(setup_path))\n",
    "# nessiedemo = importlib.util.module_from_spec(spec)\n",
    "# spec.loader.exec_module(nessiedemo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO this can probably be simpler\n",
    "\n",
    "from nessiedemo.demo import NessieDemo\n",
    "demo = NessieDemo(\"nessie-0.5-iceberg-0.11.yml\")\n",
    "dataset = demo.fetch_dataset(\"region-nation\")\n",
    "\n",
    "demo.start()\n",
    "\n",
    "# This is separate, because NessieDemo.prepare() via .start() implicitly installs the required dependencies\n",
    "from nessiedemo.spark import NessieDemoSpark\n",
    "demo_spark = NessieDemoSpark(demo)\n",
    "\n",
    "spark, sc, jvm = demo_spark.get_or_create_spark_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# session for dev branch\n",
    "spark_dev = spark.newSession()\n",
    "spark_dev.conf.set(\"spark.sql.catalog.nessie.ref\", \"dev\" )\n",
    "\n",
    "# session for ETL branch\n",
    "spark_etl = spark.newSession()\n",
    "spark_etl.conf.set(\"spark.sql.catalog.nessie.ref\", \"etl\" )\n",
    "\n",
    "# session for experiment branch\n",
    "spark_experiment = spark.newSession()\n",
    "spark_experiment.conf.set(\"spark.sql.catalog.nessie.ref\", \"experiment\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!nessie branch dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "catalog = jvm.CatalogUtil.loadCatalog(\"org.apache.iceberg.nessie.NessieCatalog\", \"nessie\", {'ref': 'dev', 'url': 'http://localhost:19120/api/v1', \"warehouse\": 'file://' + os.getcwd() + '/spark_warehouse'}, sc._jsc.hadoopConfiguration())\n",
    "\n",
    "# Creating region table\n",
    "region_name = jvm.TableIdentifier.parse(\"testing.region\")\n",
    "region_schema = jvm.Schema([\n",
    "    jvm.Types.NestedField.optional(1, \"R_REGIONKEY\", jvm.Types.LongType.get()),\n",
    "    jvm.Types.NestedField.optional(2, \"R_NAME\", jvm.Types.StringType.get()),\n",
    "    jvm.Types.NestedField.optional(3, \"R_COMMENT\", jvm.Types.StringType.get()),\n",
    "])\n",
    "region_spec = jvm.PartitionSpec.unpartitioned()\n",
    "\n",
    "region_table = catalog.createTable(region_name, region_schema, region_spec)\n",
    "region_df = spark_dev.read.load(dataset[\"region.parquet\"])\n",
    "region_df.write.format(\"iceberg\").mode(\"overwrite\").save(\"nessie.testing.region\")\n",
    "\n",
    "# Creating nation table\n",
    "nation_name = jvm.TableIdentifier.parse(\"testing.nation\")\n",
    "nation_schema = jvm.Schema([\n",
    "    jvm.Types.NestedField.optional(1, \"N_NATIONKEY\", jvm.Types.LongType.get()),\n",
    "    jvm.Types.NestedField.optional(2, \"N_NAME\", jvm.Types.StringType.get()),\n",
    "    jvm.Types.NestedField.optional(3, \"N_REGIONKEY\", jvm.Types.LongType.get()),\n",
    "    jvm.Types.NestedField.optional(4, \"N_COMMENT\", jvm.Types.StringType.get()),\n",
    "])\n",
    "nation_spec = jvm.PartitionSpec.builderFor(nation_schema).truncate(\"N_NAME\", 2).build()\n",
    "nation_table = catalog.createTable(nation_name, nation_schema, nation_spec)\n",
    "\n",
    "nation_df = spark_dev.read.load(dataset[\"nation.parquet\"])\n",
    "nation_df.write.format(\"iceberg\").mode(\"overwrite\").save(\"nessie.testing.nation\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}