{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nessie Spark SQL Demo with NBA Dataset\n",
    "============================\n",
    "This demo showcases how to use Nessie Python API along with Spark3 with Deltalake\n",
    "\n",
    "Initialize Pyspark + Nessie environment\n",
    "----------------------------------------------\n",
    "To get started, we will first have to do a few setup steps that give us everything we need\n",
    "to get started with Nessie. The `nessiedemo` lib configures all required dependencies, downloads and\n",
    "configures Spark.\n",
    "In case you're interested in the detailed setup steps for Spark, you can check out the [docs](https://projectnessie.org/tools/spark/)\n",
    "or also directly have a look into the source code of the `nessiedemo` lib [here](https://github.com/projectnessie/nessie-demos/blob/main/pydemolib/nessiedemo/spark.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# install the nessiedemo lib, which configures all required dependencies\n",
    "!pip install nessiedemo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Setup the Demo: installs the required Python dependencies, downloads the sample datasets and\n",
    "# downloads + starts the Nessie-Quarkus-Runner.\n",
    "from nessiedemo.demo import setup_demo\n",
    "demo = setup_demo(\"in-development/nessie-0.6-delta-spark3.yml\", [\"nba\"])\n",
    "\n",
    "# This is separate, because NessieDemo.prepare() via .start() implicitly installs the required dependencies.\n",
    "# Downloads Spark and sets up SparkSession, SparkContext, JVM-gateway\n",
    "from nessiedemo.delta_spark import delta_spark_for_demo\n",
    "spark, sc, jvm, demo_delta_spark = delta_spark_for_demo(demo, spark_version=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up Nessie branches (via Nessie CLI)\n",
    "----------------------------\n",
    "Once all dependencies are configured, we can get started with `Nessie` by using the\n",
    "Nessie CLI, which allows interaction with Nessie branches and tables. We'll get started with the following steps:\n",
    "\n",
    "- Create a new branch named `dev`\n",
    "- List all branches\n",
    "\n",
    "It is worth mentioning that we don't have to explicitly create a `main` branch, since it's the default branch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new `dev` branch\n",
    "!nessie branch dev\n",
    "\n",
    "# Switch Spark session to the `dev` branch, which will be used later on\n",
    "demo_delta_spark.change_ref(\"dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all branches with their revisions. We should see the `main` & `dev` branches.\n",
    "!nessie --verbose branch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create tables under dev branch\n",
    "-------------------------------------\n",
    "Once we created the `dev` branch and verified that it exists, we can use the `spark_dev` session (that points to the `dev` branch)\n",
    "to create some tables and add some data.\n",
    "\n",
    "We create two tables under the `dev` branch using the `spark_dev` session:\n",
    "- `salaries`\n",
    "- `totals_stats`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "dataset = demo.fetch_dataset(\"nba\")\n",
    "\n",
    "# Creating `salaries` table\n",
    "spark.sql(\"CREATE TABLE IF NOT EXISTS nessie_nba_salaries (Season STRING, Team STRING, Salary STRING, Player STRING) USING delta LOCATION '{}'\".format(demo_delta_spark.table_path(\"nessie_nba_salaries\")))\n",
    "salaries_df = spark.read.csv(dataset[\"salaries.csv\"], header=True)\n",
    "salaries_df.write.option('hadoop.nessie.ref', 'dev').format(\"delta\")\\\n",
    "    .mode(\"overwrite\").save(demo_delta_spark.table_path(\"nessie_nba_salaries\"))\n",
    "\n",
    "# Creating `totals_stats` table\n",
    "spark.sql(\"CREATE TABLE IF NOT EXISTS nessie_nba_totals_stats (Season STRING, Age STRING, Team STRING, ORB STRING, DRB STRING, TRB STRING, AST STRING, STL STRING, BLK STRING, TOV STRING, PTS STRING, Player STRING, RSorPO STRING) USING delta LOCATION '{}'\".format(demo_delta_spark.table_path(\"nessie_nba_totals_stats\")))\n",
    "totals_stats_df = spark.read.csv(dataset[\"totals_stats.csv\"], header=True)\n",
    "totals_stats_df.write.option('hadoop.nessie.ref', 'dev').format(\"delta\")\\\n",
    "    .mode(\"overwrite\").save(demo_delta_spark.table_path(\"nessie_nba_totals_stats\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# The `spark` session points to the `dev` branch.\n",
    "# Unlike Iceberg, Delta does not support referencing other Nessie references (branches, tags) using the `@reference` syntax.\n",
    "\n",
    "spark.sql(\"select * from nessie_nba_salaries\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check generated tables\n",
    "----------------------------\n",
    "Since we have been working solely on the `dev` branch, where we created 2 tables and added some data,\n",
    "let's verify that the `main` branch was not altered by our changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# There are no tables on the `main` branch\n",
    "!nessie contents --list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We should see the `salaries` & `totals_stats` tables on the dev branch\n",
    "!nessie contents --list --ref dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can also verify that the `dev` and `main` branches point to different commits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all branches with their revisions, where the revision of `main` should be different from `dev`\n",
    "!nessie --verbose branch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dev promotion into main\n",
    "-----------------------\n",
    "Once we are done with our changes on the `dev` branch, we would like to merge those changes into `main`.\n",
    "We merge `dev` into `main` via the Nessie CLI.\n",
    "Both branches should be at the same revision after merging/promotion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge `dev` into `main`\n",
    "!nessie merge dev -b main --force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all branches with their revisions, where the revision of main=dev\n",
    "!nessie --verbose branch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Create `etl` branch\n",
    "----------------------\n",
    "In this section we'll be simulating what a nightly ETL job might do in terms of changes.\n",
    "\n",
    "- Create a branch `etl` out of `main`\n",
    "- add data to `salaries`\n",
    "- alter the schema of `totals_stats`\n",
    "- create table `allstar_games_stats`\n",
    "- query the tables in `etl`\n",
    "- query the tables in `main`\n",
    "- promote `etl` branch to `main`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the `etl` branch based on `main`\n",
    "!nessie branch etl main\n",
    "\n",
    "# Switch Spark session to the `etl` branch, which will be used later on\n",
    "demo_delta_spark.change_ref(\"etl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# add some salaries for Kevin Durant\n",
    "from pyspark.sql import Row\n",
    "Salary = Row(\"Season\", \"Team\", \"Salary\", \"Player\")\n",
    "kevin_durant = spark.createDataFrame([\n",
    "    Salary(\"2017-18\", \"Golden State Warriors\", \"$25000000\", \"Kevin Durant\"),\n",
    "    Salary(\"2018-19\", \"Golden State Warriors\", \"$30000000\", \"Kevin Durant\"),\n",
    "    Salary(\"2019-20\", \"Brooklyn Nets\", \"$37199000\", \"Kevin Durant\"),\n",
    "    Salary(\"2020-21\", \"Brooklyn Nets\", \"$39058950\", \"Kevin Durant\")])\n",
    "kevin_durant.write.option('hadoop.nessie.ref', 'etl').format(\"delta\")\\\n",
    "    .mode(\"append\").save(demo_delta_spark.table_path(\"nessie_nba_salaries\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating `allstar_games_stats` table and viewing the contents\n",
    "spark.sql(\"CREATE TABLE IF NOT EXISTS nessie_nba_allstar_games_stats (Season STRING, Age STRING, Team STRING, ORB STRING, TRB STRING, AST STRING, STL STRING, BLK STRING, TOV STRING, PF STRING, PTS STRING, Player STRING) USING delta LOCATION '{}'\".format(demo_delta_spark.table_path(\"nessie_nba_allstar_games_stats\")))\n",
    "allstar_games_stats_df = spark.read.csv(dataset[\"allstar_games_stats.csv\"], header=True)\n",
    "allstar_games_stats_df.write.option('hadoop.nessie.ref', 'etl').format(\"delta\")\\\n",
    "    .mode(\"overwrite\").save(demo_delta_spark.table_path(\"nessie_nba_allstar_games_stats\"))\n",
    "\n",
    "spark.sql(\"select * from nessie_nba_allstar_games_stats\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we have been working on the `etl` branch, the `allstar_games_stats` table is not on the `main` branch\n",
    "!nessie contents --list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We should see `allstar_games_stats` on the `etl` branch\n",
    "!nessie contents --list --ref etl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Now merge the `etl` branch into `main`\n",
    "!nessie merge etl -b main --force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# The `etl` and `main` branch should have the same revision\n",
    "!nessie --verbose branch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `experiment` branch\n",
    "--------------------------------\n",
    "As a data analyst we might want to carry out some experiments with some data, without affecting `main` in any way.\n",
    "As in the previous examples, we can just get started by creating an `experiment` branch off of `main`\n",
    "and carry out our experiment, which could consist of the following steps:\n",
    "- drop `totals_stats` table\n",
    "- add data to `salaries` table\n",
    "- compare `experiment` and `main` tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the `experiment` branch from `main`\n",
    "!nessie branch experiment main\n",
    "\n",
    "# Switch Spark session to the `experiment` branch\n",
    "demo_delta_spark.change_ref(\"experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the `totals_stats` table on the `experiment` branch\n",
    "spark.sql(\"DROP TABLE IF EXISTS nessie_nba_totals_stats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add some salaries for Dirk Nowitzki\n",
    "Salary = Row(\"Season\", \"Team\", \"Salary\", \"Player\")\n",
    "dirk_nowitzki = spark.createDataFrame([\n",
    "    Salary(\"2015-16\", \"Dallas Mavericks\", \"$8333333\", \"Dirk Nowitzki\"),\n",
    "    Salary(\"2016-17\", \"Dallas Mavericks\", \"$25000000\", \"Dirk Nowitzki\"),\n",
    "    Salary(\"2017-28\", \"Dallas Mavericks\", \"$5000000\", \"Dirk Nowitzki\"),\n",
    "    Salary(\"2018-19\", \"Dallas Mavericks\", \"$5000000\", \"Dirk Nowitzki\")])\n",
    "dirk_nowitzki.write.option('hadoop.nessie.ref', 'experiment').format(\"delta\")\\\n",
    "    .mode(\"append\").save(demo_delta_spark.table_path(\"nessie_nba_salaries\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We should see the salaries and `allstar_games_stats` tables only (since we just dropped `totals_stats`)\n",
    "!nessie contents --list --ref experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# `main` hasn't been changed changed and still has the `totals_stats` table\n",
    "!nessie contents --list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the contents of the `salaries` table on the `experiment` branch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to the `experiment` branch.\n",
    "demo_delta_spark.change_ref(\"experiment\")\n",
    "spark.sql(\"select count(*) from nessie_nba_salaries\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compare to the contents of the `salaries` table on the `main` branch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Switch back to the `main` branch.\n",
    "demo_delta_spark.change_ref(\"main\")\n",
    "spark.sql(\"select count(*) from nessie_nba_salaries\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}